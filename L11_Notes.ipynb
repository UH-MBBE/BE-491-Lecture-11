{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11: Classifier Model Evalutation Metrics\n",
    "These notes build off the code we wrote in lecture 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning diagram](./ml_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, set up a virtual environment (venv)\n",
    "\n",
    "In the terminal (or command line interface), run this command to create a virtual environment: `python -m venv venv` or `python3 -m venv venv`\n",
    "\n",
    "To start the virtual environment with a mac run the command: `source venv/bin/activate` <br>\n",
    "To start the virtual environment with a PC and git bash run the command: `source venv/Scripts/activate`\n",
    "`\n",
    "\n",
    "Check which python environment you are in using the command: `which python`\n",
    "\n",
    "The purpose of virtual environments is to allow you to install different versions of python packages for different projects on your computer. I recommend setting up a virtual environment before installing Python packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the dependencies\n",
    "\n",
    "The packages required to run this repository are in requirements.txt\n",
    "\n",
    "To install them, run the command:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, matplotlib, and the neccessary functions from scikit-learn\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using pandas and the read_csv function\n",
    "thyroid_df = pd.read_csv('data/thyroid_data.csv')\n",
    "\n",
    "thyroid_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the shape of the dataframe\n",
    "thyroid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the fraction of rows where Recurred is 'Yes' or 'No' using the value_counts method\n",
    "thyroid_df['Recurred'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing (one hot encoding)\n",
    "Transform categorical features into a ML-compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the columns names of categorical features\n",
    "columns_to_exclude = ['Age', 'Recurred']\n",
    "\n",
    "categorical_columns = [col for col in thyroid_df.columns if col not in columns_to_exclude]\n",
    "\n",
    "categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scikit learn column transformer that will encode the categorical columns using the OneHotEncoder\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # This leaves the excluded columns unchanged\n",
    ")\n",
    "\n",
    "# Apply the transformer to the DataFrame using the fit_transform method\n",
    "transformed_data = column_transformer.fit_transform(thyroid_df)\n",
    "\n",
    "type(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of the encoded features using the get_feature_names_out function\n",
    "encoded_feature_names = column_transformer.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "\n",
    "encoded_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all the feature names to use as column values in the DataFrame\n",
    "all_feature_names = list(encoded_feature_names) + ['Age', 'Recurred']\n",
    "\n",
    "all_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using the transformed data with column names from the all_feature_names list\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=all_feature_names)\n",
    "\n",
    "transformed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the shape of the transformed dataframe\n",
    "transformed_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing (split data into training and testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the transformed dataframe into a features dataframe and target series\n",
    "X = transformed_df.drop('Recurred', axis=1)\n",
    "\n",
    "y = transformed_df['Recurred']\n",
    "\n",
    "\n",
    "# inspect feature dataframe\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect target series\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets. The training set should have 283 samples, and the testing set should have 100 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate that the training and testing sets have the correct number of samples\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the training data to perform grid search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'class_weight': ['balanced'],  # Assuming you want to keep this fixed\n",
    "    'criterion': ['gini', 'entropy'],  # Assuming you want to keep this fixed\n",
    "    'max_depth': [2, 4, 8],  # Exploring values around 4\n",
    "    'max_features': ['sqrt'],  # Assuming you want to keep this fixed\n",
    "    'n_estimators': [30, 60, 90]  # Exploring values around 60\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=2, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to your data (X_train, y_train)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print the best parameters found by the GridSearchCV using the best_params_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy score of the model with the best parameters\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model using the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new RandomForestClassifier model with the best parameters\n",
    "final_model = RandomForestClassifier(\n",
    "  class_weight='balanced', \n",
    "  criterion='entropy',\n",
    "  max_depth=8,\n",
    "  max_features='sqrt',\n",
    "  n_estimators=90,\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on your training data\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model with the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the score function to get the accuracy of the model on the testing data\n",
    "final_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a plot the feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the feature importances\n",
    "feature_importances = final_model.feature_importances_\n",
    "\n",
    "feature_importances_df = pd.DataFrame({'feature': X.columns, 'importance': feature_importances})\n",
    "\n",
    "# sort the dataframe so the most important features are at the top\n",
    "feature_importances_df.sort_values('importance', ascending=False, inplace=True)\n",
    "\n",
    "feature_importances_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature importances as a bar chart using .plot.bar()\n",
    "feature_importances_df.plot.bar(x='feature', y='importance', rot=90, figsize=(13, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Lecture 11\n",
    "### Let's look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the confusion matrix for the random forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the values of the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the associated evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sensitivity (true positive rate, recall) from the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specificity (true negative rate) from the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get precision (positive predictive value) from the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the negative predictive value from the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at area under the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train K-nearest neighbors and Support Vector Machine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](metric_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a k-nearest neighbors model and look at metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a KNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at area under the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity\n",
    "\n",
    "### Train a support vector machine classifier model and look at metrics\n",
    "Use the hyperparameters: C=0.01, class_weight='balanced', kernel='linear', gamma='scale' to match what was used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an SVM classifier model\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert report_svm[75:78] == '.83'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at area under the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert roc_auc_svm > 0.921\n",
    "assert roc_auc_svm < 0.922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
